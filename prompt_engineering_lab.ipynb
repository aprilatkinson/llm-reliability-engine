{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a257fb3",
   "metadata": {},
   "source": [
    "# LLM Reliability Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098e021",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a32116f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Environment ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"✅ Environment ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c38b0",
   "metadata": {},
   "source": [
    "### LLM Call Helper\n",
    "\n",
    "The LLM call helper provides a single interface for interacting with the language model throughout the project.\n",
    "\n",
    "Instead of calling the model directly in multiple locations, this function centralizes all model interactions. This approach improves maintainability, consistency, and reproducibility during testing.\n",
    "\n",
    "The helper serves several purposes:\n",
    "\n",
    "- **Consistency**: Ensures all prompts use the same model configuration and parameters.\n",
    "- **Control**: Allows temperature and model settings to be adjusted from a single location.\n",
    "- **Reproducibility**: Enables deterministic testing by setting temperature to 0 during reliability evaluation.\n",
    "- **Scalability**: Simplifies future extensions such as logging, response validation, or retry logic.\n",
    "\n",
    "In production AI systems, abstraction layers like this are commonly used to separate business logic from model interaction, making evaluation and iteration safer and more controlled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e90ebabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe76a0",
   "metadata": {},
   "source": [
    "### Multi-Run Testing Engine\n",
    "\n",
    "Large Language Models are probabilistic systems, meaning that identical prompts can produce different outputs across multiple executions. A prompt that appears correct in a single test may still fail when used repeatedly in production.\n",
    "\n",
    "To evaluate prompt reliability, this function executes the same prompt multiple times and records all responses. This enables systematic identification of failure patterns such as:\n",
    "\n",
    "- format drift\n",
    "- inconsistent field naming\n",
    "- variation in structure or wording\n",
    "- unexpected additional explanations\n",
    "\n",
    "By analyzing outputs across multiple runs (5, 10, and 15 iterations), reliability can be measured empirically rather than assumed from a single successful response.\n",
    "\n",
    "This approach mirrors real-world AI quality assurance workflows, where prompt behavior is validated through repeated testing before deployment into production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7fde2d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_tests(prompt, runs=5, delay=1, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    results = []\n",
    "    for i in tqdm(range(runs)):\n",
    "        output = call_llm(prompt, temperature=temperature, model=model)\n",
    "        results.append({\"run\": i + 1, \"output\": output})\n",
    "        time.sleep(delay)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a94cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_results(results, filepath):\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"✅ Results saved to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecc7f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'run': 1, 'output': 'OK'},\n",
       " {'run': 2, 'output': 'OK'},\n",
       " {'run': 3, 'output': 'OK'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prompt = \"Reply with exactly one word: OK\"\n",
    "outputs = run_multiple_tests(test_prompt, runs=3, delay=1)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e2937",
   "metadata": {},
   "source": [
    "### V1 uncontrolled generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9953cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_v1 = \"\"\"\n",
    "Extract information from this customer feedback:\n",
    "\n",
    "\"I ordered item #12345 on March 15th. The delivery was fast but the packaging was damaged.\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7888074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Order Number:** #12345\n",
      "- **Order Date:** March 15th\n",
      "- **Delivery Speed:** Fast\n",
      "- **Issue:** Damaged packaging\n"
     ]
    }
   ],
   "source": [
    "print(call_llm(extraction_prompt_v1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d20b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_runs(results, n=5):\n",
    "    for r in results[:n]:\n",
    "        print(f\"Run {r['run']}: {r['output']}\\n---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f23bde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: The sentiment of the customer message is positive.\n",
      "---\n",
      "Run 2: The sentiment of the customer message is positive.\n",
      "---\n",
      "Run 3: The sentiment of the customer message is positive.\n",
      "---\n",
      "Run 4: The sentiment of the customer message is positive.\n",
      "---\n",
      "Run 5: The sentiment of the customer message is positive.\n",
      "---\n",
      "✅ Results saved to results/sentiment_v1_runs5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_v1_runs_5 = run_multiple_tests(sentiment_prompt_v1, runs=5, delay=1)\n",
    "preview_runs(sentiment_v1_runs_5)\n",
    "save_results(sentiment_v1_runs_5, \"results/sentiment_v1_runs5.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f2335",
   "metadata": {},
   "source": [
    "### Extraction Task — Baseline Testing (v1, 5 Runs)\n",
    "\n",
    "The initial extraction prompt (v1) represents a zero-shot baseline without structural constraints or output formatting requirements.\n",
    "\n",
    "The objective of this stage is to observe how the model behaves when given minimal guidance and to identify reliability issues that may emerge across repeated executions.\n",
    "\n",
    "The prompt is executed five times using identical inputs to evaluate:\n",
    "\n",
    "- consistency of output structure\n",
    "- stability of field naming\n",
    "- presence of additional explanatory text\n",
    "- variation in how extracted information is represented\n",
    "\n",
    "At this stage, variability is expected. The goal is not correctness alone, but to identify failure patterns that could affect downstream systems relying on structured outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a04894d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: - **Order Number:** #12345\n",
      "- **Order Date:** March 15th\n",
      "- **Delivery Speed:** Fast\n",
      "- **Issue:** Damaged packaging\n",
      "---\n",
      "Run 2: - **Order Number**: #12345\n",
      "- **Order Date**: March 15th\n",
      "- **Delivery Speed**: Fast\n",
      "- **Issue**: Damaged packaging\n",
      "---\n",
      "Run 3: - **Order Number**: #12345\n",
      "- **Order Date**: March 15th\n",
      "- **Delivery Speed**: Fast\n",
      "- **Issue**: Damaged packaging\n",
      "---\n",
      "Run 4: - **Order Number**: #12345\n",
      "- **Order Date**: March 15th\n",
      "- **Delivery Speed**: Fast\n",
      "- **Issue**: Damaged packaging\n",
      "---\n",
      "Run 5: - **Order Number**: #12345\n",
      "- **Order Date**: March 15th\n",
      "- **Delivery Speed**: Fast\n",
      "- **Issue**: Damaged packaging\n",
      "---\n",
      "✅ Results saved to results/extraction_v1_runs5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extraction_v1_runs_5 = run_multiple_tests(extraction_prompt_v1, runs=5, delay=1)\n",
    "preview_runs(extraction_v1_runs_5)\n",
    "save_results(extraction_v1_runs_5, \"results/extraction_v1_runs5.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28bd10cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- **Order Number**: #12345\\n- **Order Date**: March 15th\\n- **Delivery Speed**: Fast\\n- **Issue**: Damaged packaging'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_v1_runs_5[-1][\"output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b94c39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def unique_output_count(results):\n",
    "    outputs = [r[\"output\"] for r in results]\n",
    "    return len(set(outputs)), Counter(outputs).most_common(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "494d0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to results/extraction_v1_runs10.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " [('Here is the extracted information from the customer feedback:\\n\\n- **Order Number**: #12345\\n- **Order Date**: March 15th\\n- **Delivery Speed**: Fast\\n- **Packaging Condition**: Damaged',\n",
       "   6),\n",
       "  ('- **Order Number**: #12345\\n- **Order Date**: March 15th\\n- **Delivery Speed**: Fast\\n- **Packaging Condition**: Damaged',\n",
       "   3),\n",
       "  ('- **Order Number**: #12345\\n- **Order Date**: March 15th\\n- **Delivery Speed**: Fast\\n- **Issue**: Damaged packaging',\n",
       "   1)])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_v1_runs_10 = run_multiple_tests(extraction_prompt_v1, runs=10, delay=1)\n",
    "save_results(extraction_v1_runs_10, \"results/extraction_v1_runs10.json\")\n",
    "\n",
    "unique_output_count(extraction_v1_runs_10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194c8a7",
   "metadata": {},
   "source": [
    "### V2 structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a2d1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt_v2 = \"\"\"\n",
    "Classify the sentiment of the following customer message.\n",
    "\n",
    "Respond with ONLY one word.\n",
    "Allowed responses:\n",
    "Positive\n",
    "Negative\n",
    "Neutral\n",
    "\n",
    "Customer message:\n",
    "\"I love this product! It's exactly what I needed.\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3639a773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(call_llm(sentiment_prompt_v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83032b",
   "metadata": {},
   "source": [
    "### Product Description Generation — Structured Prompt (v2)\n",
    "\n",
    "The initial product description prompt (v1) produced outputs with significant variation in length, tone, and structure. While variability is expected in generative tasks, uncontrolled variation can lead to inconsistent brand messaging and unpredictable content quality.\n",
    "\n",
    "In this iteration, explicit structural constraints are introduced to guide model behavior while preserving creative flexibility. The prompt specifies:\n",
    "\n",
    "- target length range\n",
    "- tone and style expectations\n",
    "- inclusion requirements\n",
    "- formatting restrictions\n",
    "\n",
    "The objective is not to eliminate variation entirely, but to reduce unwanted variability and improve consistency across repeated executions. This reflects real-world content generation workflows where AI outputs must remain aligned with brand and editorial standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b66abd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_prompt_v2 = \"\"\"\n",
    "Create a product description for a wireless mouse that costs $29.99.\n",
    "\n",
    "Requirements:\n",
    "- Length: 60–80 words\n",
    "- Professional marketing tone\n",
    "- Include price once\n",
    "- Do not include headings or bullet points\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "276f0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_v2 = \"\"\"\n",
    "Extract information from the customer feedback below.\n",
    "\n",
    "Return the result in EXACTLY this format.\n",
    "Do not add explanations or additional text.\n",
    "\n",
    "Order Number:\n",
    "Order Date:\n",
    "Delivery Speed:\n",
    "Issue:\n",
    "\n",
    "Customer feedback:\n",
    "\"I ordered item #12345 on March 15th. The delivery was fast but the packaging was damaged.\"\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ae0a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [('Order Number: 12345  \\nOrder Date: March 15th  \\nDelivery Speed: Fast  \\nIssue: Packaging was damaged',\n",
       "   4),\n",
       "  ('Order Number: 12345  \\nOrder Date: March 15th  \\nDelivery Speed: Fast  \\nIssue: Damaged packaging',\n",
       "   1)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_v2_runs_5 = run_multiple_tests(extraction_prompt_v2, runs=5, delay=1)\n",
    "unique_output_count(extraction_v2_runs_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e9d982",
   "metadata": {},
   "source": [
    "Based on the failure analysis from v1 testing, the prompts were updated to introduce explicit structure and output constraints.\n",
    "\n",
    "The goal of v2 is to reduce variability caused by:\n",
    "- format drift\n",
    "- inconsistent field naming\n",
    "- additional explanatory text\n",
    "\n",
    "No few-shot examples or reasoning steps are introduced yet. The focus is purely on structural consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffbb47",
   "metadata": {},
   "source": [
    "After introducing explicit output structure requirements, the number of unique outputs decreased significantly compared to v1.\n",
    "\n",
    "The model consistently returned the same schema and avoided introductory explanations, demonstrating that structural constraints alone can dramatically improve reliability in extraction tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "18d739b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:21<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to results/extraction_v2_runs10.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [('Order Number: 12345  \\nOrder Date: March 15th  \\nDelivery Speed: Fast  \\nIssue: Packaging was damaged',\n",
       "   5),\n",
       "  ('Order Number: 12345  \\nOrder Date: March 15th  \\nDelivery Speed: Fast  \\nIssue: Damaged packaging',\n",
       "   5)])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_v2_runs_10 = run_multiple_tests(\n",
    "    extraction_prompt_v2,\n",
    "    runs=10,\n",
    "    delay=1\n",
    ")\n",
    "\n",
    "save_results(\n",
    "    extraction_v2_runs_10,\n",
    "    \"results/extraction_v2_runs10.json\"\n",
    ")\n",
    "\n",
    "unique_output_count(extraction_v2_runs_10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3f5a3",
   "metadata": {},
   "source": [
    "After introducing explicit structural constraints, output variability was reduced from four unique formats in v1 to two in v2. The remaining variation occurred only in value phrasing (\"Packaging was damaged\" vs \"Damaged packaging\"), while the schema and structure remained stable.\n",
    "\n",
    "This demonstrates that structural constraints alone significantly improve reliability, but do not fully eliminate semantic variation in generated outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d29a93",
   "metadata": {},
   "source": [
    "### V3 structured reasoning + consistent behavior\n",
    "While structural constraints in v2 significantly improved output consistency, reliability can still degrade when inputs become more complex or ambiguous.\n",
    "\n",
    "In this iteration, advanced prompt engineering techniques are introduced:\n",
    "\n",
    "- Few-shot prompting to demonstrate the desired output behavior through examples\n",
    "- Chain-of-Thought reasoning to guide the model through intermediate reasoning steps before producing structured output\n",
    "\n",
    "The goal of v3 is to improve robustness and maintain consistent behavior across a wider range of inputs while preserving the structured format introduced in v2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f6f08",
   "metadata": {},
   "source": [
    "### Structured LLM Output Helper (JSON Mode)\n",
    "\n",
    "In production AI systems, model outputs are often consumed by downstream applications such as databases, automation workflows, or analytics pipelines. Free-form text responses introduce reliability risks because small variations in formatting can break parsing logic.\n",
    "\n",
    "This helper function extends the standard LLM call by enforcing structured JSON output using the model’s response formatting capabilities. By requiring valid JSON responses:\n",
    "\n",
    "- outputs become machine-readable and pipeline-safe\n",
    "- format drift is significantly reduced\n",
    "- schema validation becomes possible\n",
    "- automated evaluation and reliability scoring can be applied\n",
    "\n",
    "This approach reflects real-world AI system design, where structured outputs are preferred over natural language responses when consistency and automation are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "09209c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_json(prompt, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74f1cb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_v3 = \"\"\"\n",
    "You are an information extraction engine. Extract structured fields from customer feedback.\n",
    "\n",
    "Think step-by-step internally to identify the correct values, normalize wording, and map to the schema.\n",
    "Do NOT output your reasoning. Output ONLY valid JSON.\n",
    "\n",
    "Schema (required keys):\n",
    "{\n",
    "  \"order_number\": \"string or null\",\n",
    "  \"order_date\": \"string or null\",\n",
    "  \"delivery_speed\": \"fast|normal|slow|null\",\n",
    "  \"issue\": \"damaged_packaging|late_delivery|wrong_item|missing_items|customer_support|other|null\"\n",
    "}\n",
    "\n",
    "Normalization rules:\n",
    "- order_number: digits only (e.g., \"12345\")\n",
    "- delivery_speed: map phrases to one of fast/normal/slow\n",
    "- issue: choose the closest enum value (e.g., packaging damaged → \"damaged_packaging\")\n",
    "\n",
    "Examples:\n",
    "\n",
    "Feedback: \"Order #555 arrived late and the box was crushed.\"\n",
    "JSON:\n",
    "{\"order_number\":\"555\",\"order_date\":null,\"delivery_speed\":\"slow\",\"issue\":\"damaged_packaging\"}\n",
    "\n",
    "Feedback: \"I ordered item #999 on April 2. Delivery was quick but support never replied.\"\n",
    "JSON:\n",
    "{\"order_number\":\"999\",\"order_date\":\"April 2\",\"delivery_speed\":\"fast\",\"issue\":\"customer_support\"}\n",
    "\n",
    "Now extract from this feedback:\n",
    "\"I ordered item #12345 on March 15th. The delivery was fast but the packaging was damaged.\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0e1a1967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order_number': '12345',\n",
       " 'order_date': 'March 15th',\n",
       " 'delivery_speed': 'fast',\n",
       " 'issue': 'damaged_packaging'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_llm_json(extraction_prompt_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "856e880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:28<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to results/extraction_v3_runs15.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_multiple_tests_json(prompt, runs=15, delay=1, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    results = []\n",
    "    for i in tqdm(range(runs)):\n",
    "        obj = call_llm_json(prompt, temperature=temperature, model=model)\n",
    "        valid, reason = eval_extraction_json(obj)\n",
    "        results.append({\"run\": i+1, \"output\": obj, \"valid\": valid, \"reason\": reason})\n",
    "        time.sleep(delay)\n",
    "    return results\n",
    "\n",
    "extraction_v3_runs_15 = run_multiple_tests_json(extraction_prompt_v3, runs=15, delay=1)\n",
    "save_results(extraction_v3_runs_15, \"results/extraction_v3_runs15.json\")\n",
    "\n",
    "valid_rate = sum(r[\"valid\"] for r in extraction_v3_runs_15) / len(extraction_v3_runs_15)\n",
    "unique_outputs = len({json.dumps(r[\"output\"], sort_keys=True) for r in extraction_v3_runs_15})\n",
    "\n",
    "valid_rate, unique_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd3e43e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_rate: 1.0\n",
      "unique_outputs: 1\n"
     ]
    }
   ],
   "source": [
    "valid_rate = sum(r[\"valid\"] for r in extraction_v3_runs_15) / len(extraction_v3_runs_15)\n",
    "unique_outputs = len({json.dumps(r[\"output\"], sort_keys=True) for r in extraction_v3_runs_15})\n",
    "\n",
    "print(\"valid_rate:\", valid_rate)\n",
    "print(\"unique_outputs:\", unique_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55b00d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_prompt_v3 = \"\"\"\n",
    "You are a sentiment classification engine.\n",
    "\n",
    "Task:\n",
    "Classify the customer message sentiment as exactly one of:\n",
    "Positive, Negative, Neutral\n",
    "\n",
    "Output rules:\n",
    "- Output ONLY the single word label.\n",
    "- No punctuation, no explanation.\n",
    "\n",
    "Examples:\n",
    "Message: \"This is amazing — I’m so happy with it.\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Message: \"Terrible experience. I want a refund.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Message: \"It arrived yesterday.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Now classify:\n",
    "Message: \"I love this product! It's exactly what I needed.\"\n",
    "Sentiment:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f698d029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(call_llm(sentiment_prompt_v3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6025e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:23<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to results/sentiment_v3_runs15.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALLOWED_SENTIMENT = {\"Positive\", \"Negative\", \"Neutral\"}\n",
    "\n",
    "def eval_sentiment(output: str):\n",
    "    return output in ALLOWED_SENTIMENT\n",
    "\n",
    "def run_multiple_tests_text(prompt, runs=15, delay=1, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    results = []\n",
    "    for i in tqdm(range(runs)):\n",
    "        out = call_llm(prompt, temperature=temperature, model=model)\n",
    "        results.append({\"run\": i+1, \"output\": out, \"valid\": eval_sentiment(out)})\n",
    "        time.sleep(delay)\n",
    "    return results\n",
    "\n",
    "sentiment_v3_runs_15 = run_multiple_tests_text(sentiment_prompt_v3, runs=15, delay=1)\n",
    "save_results(sentiment_v3_runs_15, \"results/sentiment_v3_runs15.json\")\n",
    "\n",
    "valid_rate = sum(r[\"valid\"] for r in sentiment_v3_runs_15) / len(sentiment_v3_runs_15)\n",
    "unique_outputs = len({r[\"output\"] for r in sentiment_v3_runs_15})\n",
    "\n",
    "valid_rate, unique_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8309a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Wireless Mouse with Ergonomic Shape and Silent Clicks',\n",
       " 'bullets': ['2.4GHz wireless connectivity for a reliable connection',\n",
       "  'Silent clicks for a distraction-free environment',\n",
       "  'Ergonomic shape designed for comfort during long hours of use',\n",
       "  '12-month battery life to minimize interruptions'],\n",
       " 'short_description': 'A wireless mouse featuring silent clicks and an ergonomic design, perfect for remote workers and students.',\n",
       " 'long_description': 'Enhance your productivity with this wireless mouse, designed for comfort and efficiency. The 2.4GHz wireless connectivity ensures a stable connection, while the silent clicks allow you to work without disturbing those around you. Its ergonomic shape provides support for extended use, making it ideal for remote workers and students alike. With an impressive 12-month battery life, you can focus on your tasks without the hassle of frequent recharging.',\n",
       " 'aio_snippet': 'This wireless mouse offers silent clicks and an ergonomic design, making it an excellent choice for remote workers and students seeking comfort and reliability.'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_llm_json(product_prompt_v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4149e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_prompt_v3 = \"\"\"\n",
    "You are a product copy generation engine for ecommerce.\n",
    "\n",
    "Goal:\n",
    "Generate consistent, brand-safe marketing copy from product facts.\n",
    "\n",
    "OUTPUT RULES (STRICT):\n",
    "- Output ONLY valid JSON (no markdown, no backticks, no commentary).\n",
    "- Follow the schema EXACTLY and include ALL keys.\n",
    "- Do NOT include any extra keys.\n",
    "- bullets must contain EXACTLY 3 items (no more, no fewer).\n",
    "- short_description must be <= 40 words.\n",
    "- long_description must be EXACTLY 105–110 words.\n",
    "  Count words before output. If you are outside 105–110, rewrite until within range.\n",
    "- aio_snippet must be 1–2 sentences.\n",
    "\n",
    "Brand voice:\n",
    "- Tone: premium, confident, helpful\n",
    "- Style: clear, benefit-oriented, not hypey\n",
    "\n",
    "Compliance rules (hard constraints):\n",
    "- Do NOT claim \"best\", \"#1\", \"guaranteed\", or make medical/health promises.\n",
    "- Do NOT mention competitors.\n",
    "- Do NOT invent specifications not provided.\n",
    "- If a spec is missing, omit it rather than guessing.\n",
    "\n",
    "Schema (required keys and types):\n",
    "{\n",
    "  \"title\": \"string\",\n",
    "  \"bullets\": [\"string\", \"string\", \"string\"],\n",
    "  \"short_description\": \"string\",\n",
    "  \"long_description\": \"string\",\n",
    "  \"aio_snippet\": \"string\"\n",
    "}\n",
    "\n",
    "Few-shot example (match this structure exactly):\n",
    "\n",
    "Input:\n",
    "Product: \"Stainless Steel Water Bottle\"\n",
    "Price: \"$19.99\"\n",
    "Key features: \"750ml\", \"double-wall insulation\", \"leak-proof lid\"\n",
    "Audience: \"commuters and gym users\"\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"title\": \"Stainless Steel Water Bottle (750ml) with Leak-Proof Lid\",\n",
    "  \"bullets\": [\n",
    "    \"Keeps drinks hot or cold longer with double-wall insulation\",\n",
    "    \"Leak-proof lid designed for bags and on-the-go use\",\n",
    "    \"750ml capacity suits commuting, workouts, and daily hydration\"\n",
    "  ],\n",
    "  \"short_description\": \"A durable 750ml bottle with double-wall insulation and a leak-proof lid—ideal for commuting and training.\",\n",
    "  \"long_description\": \"Stay hydrated wherever the day takes you. This 750ml stainless steel bottle features double-wall insulation to help maintain your drink’s temperature for longer. The leak-proof lid is built for life on the move—toss it in a work bag or gym backpack with confidence. With a clean, durable finish and a practical size, it’s an easy everyday upgrade for commuters and fitness routines alike.\",\n",
    "  \"aio_snippet\": \"A 750ml insulated stainless steel bottle with a leak-proof lid, designed for commuters and gym users who want reliable temperature retention on the go.\"\n",
    "}\n",
    "\n",
    "Now generate output for:\n",
    "\n",
    "Input:\n",
    "Product: \"Wireless Mouse\"\n",
    "Price: \"$29.99\"\n",
    "Key features: \"2.4GHz wireless\", \"silent clicks\", \"ergonomic shape\", \"12-month battery life\"\n",
    "Audience: \"remote workers and students\"\n",
    "\n",
    "Output:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d34c7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_tests_product_json(prompt, runs=15, delay=1, temperature=0, model=\"gpt-4o-mini\"):\n",
    "    results = []\n",
    "\n",
    "    for i in tqdm(range(runs)):\n",
    "        obj = call_llm_json(prompt, temperature=temperature, model=model)\n",
    "\n",
    "        valid, reason = eval_product_json(obj)\n",
    "\n",
    "        results.append({\n",
    "            \"run\": i + 1,\n",
    "            \"output\": obj,\n",
    "            \"valid\": valid,\n",
    "            \"reason\": reason\n",
    "        })\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "29f25d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_product_json(obj):\n",
    "    required = {\"title\", \"bullets\", \"short_description\", \"long_description\", \"aio_snippet\"}\n",
    "    if not isinstance(obj, dict):\n",
    "        return False, \"not_a_dict\"\n",
    "\n",
    "    if set(obj.keys()) != required:\n",
    "        return False, \"wrong_keys\"\n",
    "\n",
    "    if not isinstance(obj[\"title\"], str) or not obj[\"title\"].strip():\n",
    "        return False, \"bad_title\"\n",
    "\n",
    "    if not isinstance(obj[\"bullets\"], list) or len(obj[\"bullets\"]) != 3:\n",
    "        return False, \"bullets_not_3\"\n",
    "\n",
    "    if any(not isinstance(b, str) or not b.strip() for b in obj[\"bullets\"]):\n",
    "        return False, \"bad_bullets\"\n",
    "\n",
    "    # Word count checks\n",
    "    if len(obj[\"short_description\"].split()) > 40:\n",
    "        return False, \"short_too_long\"\n",
    "\n",
    "    long_wc = len(obj[\"long_description\"].split())\n",
    "    if not (90 <= long_wc <= 120):\n",
    "        return False, \"long_out_of_range\"\n",
    "\n",
    "    # Compliance check\n",
    "    banned_phrases = [\"#1\", \"best\", \"guaranteed\"]\n",
    "\n",
    "    text_all = \" \"._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "32170546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:28<00:00,  5.91s/it]\n"
     ]
    }
   ],
   "source": [
    "product_v3_runs_15 = run_multiple_tests_product_json(product_prompt_v3, runs=15, delay=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9ecd087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Results saved to results/product_v3_runs15.json\n",
      "valid_rate: 0.0\n",
      "unique_outputs: 12\n",
      "failure_reasons: {'long_out_of_range': 15}\n"
     ]
    }
   ],
   "source": [
    "save_results(product_v3_runs_15, \"results/product_v3_runs15.json\")\n",
    "\n",
    "valid_rate = sum(r[\"valid\"] for r in product_v3_runs_15) / len(product_v3_runs_15)\n",
    "unique_outputs = len({json.dumps(r[\"output\"], sort_keys=True) for r in product_v3_runs_15})\n",
    "\n",
    "reasons = {}\n",
    "for r in product_v3_runs_15:\n",
    "    reasons[r[\"reason\"]] = reasons.get(r[\"reason\"], 0) + 1\n",
    "\n",
    "print(\"valid_rate:\", valid_rate)\n",
    "print(\"unique_outputs:\", unique_outputs)\n",
    "print(\"failure_reasons:\", reasons)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
